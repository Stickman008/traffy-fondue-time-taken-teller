{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import CamembertTokenizerFast,AutoModel,AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.transformers import generate_signature_output\n",
    "import mlflow\n",
    "from torch import nn\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['ถนน','ทางเท้า','แสงสว่าง','ความปลอดภัย','น้ำท่วม','ความสะอาด','กีดขวาง',\n",
    "        'ท่อระบายน้ำ','สะพาน','จราจร','สายไฟ','คลอง','เสียงรบกวน','ต้นไม้','ร้องเรียน',\n",
    "        'ป้าย','สัตว์จรจัด',\"PM25\",'สอบถาม','เสนอแนะ','คนจรจัด','การเดินทาง','ห้องน้ำ','ป้ายจราจร']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('multilabel.pth',map_location=torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "BERT_MODEL_NAME = \"airesearch/wangchanberta-base-att-spm-uncased\"\n",
    "# model = AutoModel.from_pretrained('multilable_pretrained')\n",
    "tokenizer = CamembertTokenizerFast.from_pretrained(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    y_pred = []\n",
    "    input = tokenizer(text,padding='max_length', max_length = 256, truncation=True,return_tensors=\"pt\")\n",
    "    input = input['input_ids']\n",
    "    output = model(input).logits\n",
    "    output = F.sigmoid(output)\n",
    "    for row in output:\n",
    "        y_pred.append([1 if i>=0.5 else 0 for i in row])\n",
    "\n",
    "    y_pred_decoded = []\n",
    "    for i in y_pred:\n",
    "        tmp = []\n",
    "        for c in range(len(i)):\n",
    "            if(i[c]==1):\n",
    "                tmp.append(types[c])\n",
    "        y_pred_decoded.append(tmp)\n",
    "\n",
    "    return y_pred_decoded\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า'\n",
    "text2 = 'การทิ้งขยะลงในลำคลอง'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ทางเท้า', 'ความสะอาด']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ความสะอาด']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained('multilabel_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForSequenceClassification.from_pretrained('multilabel_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer(text, padding='max_length', max_length=256, truncation=True, return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.set_tracking_uri('http://127.0.0.1:5000')  # set up connection\n",
    "# mlflow.set_experiment('multilabel')\n",
    "# with mlflow.start_run() as run:\n",
    "#     mlflow.pytorch.save_model(model,'multilabel')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OverRide output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define your model architecture here\n",
    "        self.model = torch.load('multilabel.pth',map_location=torch.device('cpu'))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass of your model\n",
    "        # This function will be used during training, not for prediction\n",
    "        # Typically, you would define the layers and operations here\n",
    "        \n",
    "        return self.model(x).logits\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output =  generate_signature_output(model,X.numpy())\n",
    "signature = infer_signature(X.numpy(), model.predict(X).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pytorch\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')  # set up connection\n",
    "mlflow.set_experiment('multilabel')\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.pytorch.log_model(model, \"model\",signature=signature)\n",
    "model_uri = \"runs:/{}/model\".format(run.info.run_id)\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_json(server_url, input_json):\n",
    "    response = requests.post(server_url, json=input_json)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(\"Request failed with status code: %s, response: %s\"\n",
    "                        % (response.status_code, response.text))\n",
    "    \n",
    "def predict(server_url, text):\n",
    "    inputs = tokenizer(text, padding='max_length', max_length=256, truncation=True, return_tensors='pt')['input_ids']\n",
    "    # print(inputs)\n",
    "    data = {\"inputs\":inputs.numpy().tolist()}\n",
    "    # print(data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return predict_json(server_url, data)\n",
    "\n",
    "text = 'ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า'\n",
    "\n",
    "predict_result = predict(\"http://127.0.0.1:1244/invocations\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result = predict(\"http://127.0.0.1:1244/invocations\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [[-2.8791043758392334,\n",
       "   0.3272898197174072,\n",
       "   -7.104610919952393,\n",
       "   -6.118514537811279,\n",
       "   -6.331795692443848,\n",
       "   3.317025661468506,\n",
       "   -5.537487983703613,\n",
       "   -7.752892971038818,\n",
       "   -8.088247299194336,\n",
       "   -7.010658264160156,\n",
       "   -8.05642318725586,\n",
       "   -8.945622444152832,\n",
       "   -7.5058794021606445,\n",
       "   -8.085744857788086,\n",
       "   -6.152515411376953,\n",
       "   -7.692965507507324,\n",
       "   -7.599690914154053,\n",
       "   -8.028019905090332,\n",
       "   -8.24844741821289,\n",
       "   -8.690380096435547,\n",
       "   -7.523009777069092,\n",
       "   -7.622708320617676,\n",
       "   -8.261131286621094,\n",
       "   -9.733368873596191]]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_prediction(predict_result):\n",
    "    y_pred = []\n",
    "    res = np.array(predict_result['predictions'])\n",
    "    res = torch.tensor(res)\n",
    "    res = F.sigmoid(res)\n",
    "    for row in res:\n",
    "        y_pred.append([1 if i>=0.5 else 0 for i in row])\n",
    "\n",
    "    y_pred_decoded = []\n",
    "    for i in y_pred:\n",
    "        tmp = []\n",
    "        for c in range(len(i)):\n",
    "            if(i[c]==1):\n",
    "                tmp.append(types[c])\n",
    "        y_pred_decoded.append(tmp)\n",
    "\n",
    "    return y_pred_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ทางเท้า', 'ความสะอาด']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_prediction(predict_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('multilabel_pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Pipeline\n",
    "\n",
    "\n",
    "class MyPipeline(Pipeline):\n",
    "    def _sanitize_parameters(self, **kwargs):\n",
    "        preprocess_kwargs = {}\n",
    "        if \"maybe_arg\" in kwargs:\n",
    "            preprocess_kwargs[\"maybe_arg\"] = kwargs[\"maybe_arg\"]\n",
    "        return preprocess_kwargs, {}, {}\n",
    "    def preprocess(self, inputs):\n",
    "        return self.tokenizer(inputs, padding='max_length', max_length=256, truncation=True, return_tensors='pt')['input_ids']\n",
    "        \n",
    "\n",
    "    def _forward(self, model_inputs):\n",
    "        return self.model(model_inputs)\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        return model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = MyPipeline(model = model,tokenizer = tokenizer,task = \"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.transformers import generate_signature_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer(text, padding='max_length', max_length=256, truncation=True, return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model(tokenizer(text, padding='max_length', max_length=256, truncation=True, return_tensors='pt')['input_ids']).logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from mlflow.models.signature import ModelSignature\n",
    "# from mlflow.types.schema import Schema, TensorSpec\n",
    "\n",
    "# input_schema = Schema(\n",
    "#     [\n",
    "#         TensorSpec(np.dtype(np.int64), (1,256)),\n",
    "#     ]\n",
    "# )\n",
    "# output_schema = Schema([TensorSpec(np.dtype(np.float32), (1, 24))])\n",
    "# signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.predict('ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = CamembertTokenizerFast.from_pretrained(BERT_MODEL_NAME, padding='max_length', max_length=256, truncation=True, return_tensors='pt')\n",
    "# tokenizer.padding = 'max_length'  # Pad sequences to the maximum length\n",
    "# tokenizer.max_length = 256  # Set the maximum sequence length\n",
    "# tokenizer.truncation = True \n",
    "# tokenizer('ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer('ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า', padding='max_length', max_length=256, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(tokenizer('ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า', padding='max_length', max_length=256, truncation=True, return_tensors='pt')['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pytorch\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')  # set up connection\n",
    "mlflow.set_experiment('multilabel_model')\n",
    "# mlflow.transformers.autolog()\n",
    "with mlflow.start_run() as run:\n",
    "    # mlflow.transformers.save_model(\n",
    "    #     transformers_model=pipeline,\n",
    "    #     path=\"transformer_pipeline\",\n",
    "    # )\n",
    "    mlflow.transformers.log_model(\n",
    "        transformers_model=pipeline,\n",
    "        artifact_path=\"multilabel_pipeline\",\n",
    "        \n",
    "    )\n",
    "model_uri = \"runs:/{}/multilabel_pipeline\".format(run.info.run_id)\n",
    "\n",
    "loaded = mlflow.transformers.load_model(model_uri)\n",
    "loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.transformers import generate_signature_output\n",
    "text = 'ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า'\n",
    "df = pd.DataFrame([text],columns=['text'])\n",
    "output =  generate_signature_output(loaded,df)\n",
    "signature = infer_signature(df, output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.transformers.save_model(\n",
    "    transformers_model=loaded ,\n",
    "    path=\"text-class\",\n",
    "    signature=signature,\n",
    "    input_example=df,\n",
    ")\n",
    "\n",
    "loaded = mlflow.transformers.load_model(\"text-class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.transformers.log_model(\n",
    "        transformers_model=loaded,\n",
    "        artifact_path=\"multilabel_pipeline\",\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow.pytorch\n",
    "# import mlflow\n",
    "# mlflow.set_tracking_uri('http://127.0.0.1:5000')  # set up connection\n",
    "# mlflow.set_experiment('multilabel-experiment')\n",
    "# with mlflow.start_run() as run:\n",
    "#     mlflow.pytorch.log_model(model, \"model\")\n",
    "# model_uri = \"runs:/{}/model\".format(run.info.run_id)\n",
    "# model = mlflow.pytorch.load_model(model_uri)\n",
    "# model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "BERT_MODEL_NAME = \"airesearch/wangchanberta-base-att-spm-uncased\"\n",
    "tokenizer = CamembertTokenizerFast.from_pretrained(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input  = tokenizer.encode_plus(text, padding='max_length', max_length=256, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model(encoded_input['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict_json(server_url, input_json):\n",
    "    response = requests.post(server_url, json=input_json)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(\"Request failed with status code: %s, response: %s\"\n",
    "                        % (response.status_code, response.text))\n",
    "    \n",
    "def predict(server_url, df):\n",
    "    data = {\"dataframe_split\": df.to_dict(orient='split')}\n",
    "    print(data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return predict_json(server_url, data)\n",
    "\n",
    "text = 'ไม่มีที่วางขยะรอจัดเก็บ วางไว้บนทางเท้า'\n",
    "\n",
    "# def predict(text):\n",
    "#     input = tokenizer(text,padding='max_length', max_length = 256, truncation=True,return_tensors=\"pt\")\n",
    "#     input = input['input_ids'].squeeze(1).to(device)\n",
    "#     output = model(input).logits\n",
    "#     output = F.sigmoid(output)\n",
    "#     res = output.detach().cpu().numpy()\n",
    "    \n",
    "#     return output\n",
    "\n",
    "predict(\"http://127.0.0.1:1245/invocations\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"http://127.0.0.1:1245/invocations\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
