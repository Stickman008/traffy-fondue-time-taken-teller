{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/bangkok_traffy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['organization','comment','photo','photo_after','coords','address','star','count_reopen'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>type</th>\n",
       "      <th>subdistrict</th>\n",
       "      <th>district</th>\n",
       "      <th>province</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>state</th>\n",
       "      <th>last_activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-9LHDM6</td>\n",
       "      <td>{}</td>\n",
       "      <td>บางพลัด</td>\n",
       "      <td>บางพลัด</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>2021-09-01 10:44:55.353209+00</td>\n",
       "      <td>กำลังดำเนินการ</td>\n",
       "      <td>2022-02-22 04:59:58.622268+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-FYJTFP</td>\n",
       "      <td>{ความสะอาด}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>2021-09-03 12:51:09.453003+00</td>\n",
       "      <td>เสร็จสิ้น</td>\n",
       "      <td>2022-06-04 15:34:14.609206+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-8GKAR9</td>\n",
       "      <td>{สายไฟ}</td>\n",
       "      <td>สามเสนนอก</td>\n",
       "      <td>ห้วยขวาง</td>\n",
       "      <td>จังหวัดกรุงเทพมหานคร</td>\n",
       "      <td>2021-09-19 06:47:50.488685+00</td>\n",
       "      <td>กำลังดำเนินการ</td>\n",
       "      <td>2022-02-22 04:30:07.293416+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-AFPUXZ</td>\n",
       "      <td>{ถนน,สะพาน}</td>\n",
       "      <td>สีลม</td>\n",
       "      <td>บางรัก</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>2021-09-19 07:40:30.000781+00</td>\n",
       "      <td>กำลังดำเนินการ</td>\n",
       "      <td>2022-02-22 04:30:04.507406+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-CGPMUN</td>\n",
       "      <td>{น้ำท่วม,ร้องเรียน}</td>\n",
       "      <td>หนองบอน</td>\n",
       "      <td>ประเวศ</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>2021-09-19 14:56:08.924992+00</td>\n",
       "      <td>เสร็จสิ้น</td>\n",
       "      <td>2022-06-21 08:21:09.532782+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticket_id                 type subdistrict  district  \\\n",
       "0  2021-9LHDM6                   {}     บางพลัด   บางพลัด   \n",
       "1  2021-FYJTFP          {ความสะอาด}         NaN       NaN   \n",
       "2  2021-8GKAR9              {สายไฟ}   สามเสนนอก  ห้วยขวาง   \n",
       "3  2021-AFPUXZ          {ถนน,สะพาน}        สีลม    บางรัก   \n",
       "4  2021-CGPMUN  {น้ำท่วม,ร้องเรียน}     หนองบอน    ประเวศ   \n",
       "\n",
       "               province                      timestamp           state  \\\n",
       "0         กรุงเทพมหานคร  2021-09-01 10:44:55.353209+00  กำลังดำเนินการ   \n",
       "1         กรุงเทพมหานคร  2021-09-03 12:51:09.453003+00       เสร็จสิ้น   \n",
       "2  จังหวัดกรุงเทพมหานคร  2021-09-19 06:47:50.488685+00  กำลังดำเนินการ   \n",
       "3         กรุงเทพมหานคร  2021-09-19 07:40:30.000781+00  กำลังดำเนินการ   \n",
       "4         กรุงเทพมหานคร  2021-09-19 14:56:08.924992+00       เสร็จสิ้น   \n",
       "\n",
       "                   last_activity  \n",
       "0  2022-02-22 04:59:58.622268+00  \n",
       "1  2022-06-04 15:34:14.609206+00  \n",
       "2  2022-02-22 04:30:07.293416+00  \n",
       "3  2022-02-22 04:30:04.507406+00  \n",
       "4  2022-06-21 08:21:09.532782+00  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticket_id        2636\n",
       "type               97\n",
       "subdistrict        72\n",
       "district           74\n",
       "province           25\n",
       "timestamp           0\n",
       "state               0\n",
       "last_activity       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['กรุงเทพมหานคร', 'จังหวัดกรุงเทพมหานคร', 'นนทบุรี', 'นครปฐม',\n",
       "       'ศรีสะเกษ', 'สมุทรปราการ', 'เชียงใหม่', 'ปทุมธานี', 'สมุทรสาคร',\n",
       "       'อ่างทอง', 'ชลบุรี', 'ภูเก็ต', 'ยะลา', 'ลำปาง', 'พระนครศรีอยุธยา',\n",
       "       'ตาก', 'อุบลราชธานี', 'ฉะเชิงเทรา', 'ขอนแก่น', 'นครศรีธรรมราช',\n",
       "       'เชียงราย', nan, 'จันทบุรี', 'สงขลา', 'นครราชสีมา', 'ปราจีนบุรี',\n",
       "       'กาฬสินธุ์', 'พิจิตร', 'อุตรดิตถ์', 'ราชบุรี', 'กาญจนบุรี',\n",
       "       'ชัยนาท', 'อุทัยธานี', 'สุพรรณบุรี', 'ลพบุรี', 'นครสวรรค์',\n",
       "       'นครนายก', 'สกลนคร', 'สตูล', 'อุดรธานี', 'เพชรบุรี', 'ตรัง',\n",
       "       'สุรินทร์', 'อำนาจเจริญ', 'บุรีรัมย์', 'สุโขทัย', 'สุราษฎร์ธานี',\n",
       "       'พิษณุโลก', 'มหาสารคาม', 'ร้อยเอ็ด', 'แพร่', 'สมุทรสงคราม',\n",
       "       'สิงห์บุรี', 'ลำพูน', 'ระยอง', 'ยโสธร', 'นครพนม', 'น่าน',\n",
       "       'หนองบัวลำภู', 'จังหวัดชลบุรี', 'จังหวัดจังหวัด กรุงเทพมหานคร',\n",
       "       'จังหวัดพระนครศรีอยุธยา', 'จังหวัดสมุทรปราการ', 'จังหวัดLac',\n",
       "       'จังหวัดฉะเชิงเทรา', 'จังหวัดนนทบุรี', 'จังหวัดBangkok',\n",
       "       'จังหวัดจังหวัดกรุงเทพมหานคร', 'ตราด', 'เพชรบูรณ์',\n",
       "       'ประจวบคีรีขันธ์', 'จังหวัดปทุมธานี', 'จังหวัดสมุทรสาคร',\n",
       "       'ปัตตานี', 'จังหวัดจ.ฉะเชิงเทรา', 'จังหวัดสระบุรี',\n",
       "       'จังหวัดประจวบคีรีขันธ์', 'สระบุรี', 'จังหวัดลพบุรี'], dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['province'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['province'].str.contains('กรุงเทพ|bangkok',na=False,case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['type']=='{}'].time.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['subdistrict', 'district'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticket_id        2610\n",
       "type               97\n",
       "subdistrict         0\n",
       "district            0\n",
       "province            0\n",
       "timestamp           0\n",
       "state               0\n",
       "last_activity       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['state'].str.contains('เสร็จ',na=False,case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['{น้ำท่วม,ร้องเรียน}', '{สะพาน}', '{น้ำท่วม,ถนน}', ...,\n",
       "       '{ป้าย,จราจร,ถนน,คลอง}',\n",
       "       '{ร้องเรียน,ความสะอาด,เสียงรบกวน,สัตว์จรจัด}',\n",
       "       '{ถนน,จราจร,สะพาน,คลอง}'], dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "จตุจักร              9917\n",
       "ประเวศ               8833\n",
       "บางแค                7791\n",
       "บางเขน               6848\n",
       "ลาดกระบัง            6578\n",
       "บางกะปิ              6522\n",
       "วัฒนา                6372\n",
       "คลองเตย              6051\n",
       "สวนหลวง              5722\n",
       "บางขุนเทียน          5134\n",
       "บึงกุ่ม              4870\n",
       "บางซื่อ              4701\n",
       "ราชเทวี              4550\n",
       "ปทุมวัน              4539\n",
       "ดินแดง               4413\n",
       "บางกอกน้อย           4326\n",
       "ลาดพร้าว             4288\n",
       "สาทร                 4268\n",
       "บางรัก               4238\n",
       "วังทองหลาง           4186\n",
       "พญาไท                4015\n",
       "ธนบุรี               3960\n",
       "บางนา                3806\n",
       "สายไหม               3775\n",
       "พระนคร               3747\n",
       "คลองสามวา            3718\n",
       "มีนบุรี              3547\n",
       "ห้วยขวาง             3461\n",
       "บางพลัด              3418\n",
       "ภาษีเจริญ            3406\n",
       "หนองจอก              3247\n",
       "สะพานสูง             3245\n",
       "พระโขนง              3183\n",
       "หลักสี่              3178\n",
       "ดอนเมือง             3137\n",
       "จอมทอง               3135\n",
       "ตลิ่งชัน             2859\n",
       "ทุ่งครุ              2720\n",
       "หนองแขม              2716\n",
       "ป้อมปราบศัตรูพ่าย    2684\n",
       "ยานนาวา              2649\n",
       "บางคอแหลม            2461\n",
       "บางบอน               2427\n",
       "คลองสาน              2223\n",
       "ดุสิต                2191\n",
       "ราษฎร์บูรณะ          2069\n",
       "คันนายาว             1970\n",
       "ทวีวัฒนา             1967\n",
       "บางกอกใหญ่           1596\n",
       "สัมพันธวงศ์          1071\n",
       "Name: district, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.district.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subdistrict</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>หนองบอน</td>\n",
       "      <td>ประเวศ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ยานนาวา</td>\n",
       "      <td>สาทร</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ลาดพร้าว</td>\n",
       "      <td>ลาดพร้าว</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>ลาดพร้าว</td>\n",
       "      <td>ลาดพร้าว</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>ดุสิต</td>\n",
       "      <td>ดุสิต</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269635</th>\n",
       "      <td>บางยี่ขัน</td>\n",
       "      <td>บางพลัด</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269653</th>\n",
       "      <td>วงศ์สว่าง</td>\n",
       "      <td>บางซื่อ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269656</th>\n",
       "      <td>วงศ์สว่าง</td>\n",
       "      <td>บางซื่อ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269660</th>\n",
       "      <td>วงศ์สว่าง</td>\n",
       "      <td>บางซื่อ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269862</th>\n",
       "      <td>คลองจั่น</td>\n",
       "      <td>บางกะปิ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201728 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subdistrict  district\n",
       "4          หนองบอน    ประเวศ\n",
       "10         ยานนาวา      สาทร\n",
       "25        ลาดพร้าว  ลาดพร้าว\n",
       "64        ลาดพร้าว  ลาดพร้าว\n",
       "102          ดุสิต     ดุสิต\n",
       "...            ...       ...\n",
       "269635   บางยี่ขัน   บางพลัด\n",
       "269653   วงศ์สว่าง   บางซื่อ\n",
       "269656   วงศ์สว่าง   บางซื่อ\n",
       "269660   วงศ์สว่าง   บางซื่อ\n",
       "269862    คลองจั่น   บางกะปิ\n",
       "\n",
       "[201728 rows x 2 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['subdistrict','district']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "df['last_activity'] = pd.to_datetime(df['last_activity'], utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] =  (df['last_activity'] - df['timestamp']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_con = df['type'].str.strip('{}').str.get_dummies(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,type_con],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_hot =  pd.get_dummies(df['district'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,district_hot],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['ticket_id','type','subdistrict','district','province','timestamp','state','last_activity'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_rem = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "df_val, df_test = train_test_split(df_rem, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, dataframe, feature_scaler, target_scaler):\n",
    "        self.data = dataframe.to_numpy()\n",
    "        self.feature_scaler = feature_scaler\n",
    "        self.target_scaler = target_scaler\n",
    "        self.targets = self.target_scaler.transform(self.data[:, 0].reshape(-1, 1))\n",
    "        self.features = self.feature_scaler.transform(self.data[:, 1:])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_scaler = StandardScaler()\n",
    "feature_scaler.fit(df_train.iloc[:, 1:])\n",
    "\n",
    "target_scaler = StandardScaler()\n",
    "target_scaler.fit(df_train.iloc[:, 0].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\supak\\anaconda3\\envs\\torch2\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\supak\\anaconda3\\envs\\torch2\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TabularDataset(df_train, feature_scaler, target_scaler)\n",
    "test_dataset = TabularDataset(df_test, feature_scaler, target_scaler)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model class\n",
    "class TabularModel(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 128)\n",
    "        self.fc3 = torch.nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0651, -0.0367,  3.9041, -0.0624, -0.1869, -0.2616, -0.3145, -0.2060,\n",
       "         -0.1866,  1.6352, -0.3619, -0.2374, -0.3030, -0.1552, -0.0304, -0.1567,\n",
       "         -0.0645, -0.1997, -0.1133, -0.1514, -0.0310, -0.0613, -0.1897, -0.2475,\n",
       "         -0.1053, -0.1373,  5.6528, -0.0979, -0.2277, -0.1260, -0.1262, -0.1491,\n",
       "         -0.1042, -0.1193, -0.0981, -0.1164, -0.1420, -0.1492, -0.0892, -0.1839,\n",
       "         -0.1630, -0.1108, -0.1535, -0.1383, -0.1106, -0.1303, -0.1465, -0.1880,\n",
       "         -0.2009, -0.1572, -0.1522, -0.2142, -0.1155, -0.1413, -0.1376, -0.1276,\n",
       "         -0.1318, -0.1330, -0.1142, -0.1515, -0.1022, -0.1847, -0.1471, -0.1445,\n",
       "         -0.1815, -0.1704, -0.1275, -0.0713, -0.1473, -0.1390, -0.1268, -0.1158,\n",
       "         -0.1264, -0.1325]),\n",
       " tensor([-0.6204]))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabularModel(input_size=df_train.shape[1]-1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1198it [00:07, 170.30it/s]"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = 0.0\n",
    "    for i, (inputs, targets) in tqdm(enumerate(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    test_loss = 0.0\n",
    "    for i, (inputs, targets) in tqdm(enumerate(test_loader)):\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "    test_loss /= len(test_loader)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x75 and 74x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[144], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m mse, mae, rmse, df\n\u001b[0;32m     31\u001b[0m \u001b[39m# Usage:\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m test_mse, test_mae, test_rmse, results_df \u001b[39m=\u001b[39m evaluate_model(model, test_loader, feature_scaler, target_scaler)\n\u001b[0;32m     33\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTest MSE: \u001b[39m\u001b[39m{\u001b[39;00mtest_mse\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTest MAE: \u001b[39m\u001b[39m{\u001b[39;00mtest_mae\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[144], line 13\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, dataloader, feature_scaler, target_scaler)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m     12\u001b[0m     \u001b[39mfor\u001b[39;00m inputs, targets \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m---> 13\u001b[0m         outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     14\u001b[0m         loss \u001b[39m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     15\u001b[0m         total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\supak\\anaconda3\\envs\\torch2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[139], line 10\u001b[0m, in \u001b[0;36mTabularModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 10\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x))\n\u001b[0;32m     11\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x))\n\u001b[0;32m     12\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3(x)\n",
      "File \u001b[1;32mc:\\Users\\supak\\anaconda3\\envs\\torch2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\supak\\anaconda3\\envs\\torch2\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x75 and 74x128)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_model(model, dataloader, feature_scaler, target_scaler):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "            y_true.extend(targets.numpy())\n",
    "            y_pred.extend(outputs.numpy())\n",
    "    \n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    \n",
    "    # Inverse transform the scaled values\n",
    "    y_true = target_scaler.inverse_transform(y_true)\n",
    "    y_pred = target_scaler.inverse_transform(y_pred)\n",
    "    \n",
    "    df = pd.DataFrame({'Actual': y_true.flatten(), 'Predicted': y_pred.flatten()})\n",
    "    \n",
    "    return mse, mae, rmse, df\n",
    "\n",
    "# Usage:\n",
    "test_mse, test_mae, test_rmse, results_df = evaluate_model(model, test_loader, feature_scaler, target_scaler)\n",
    "print(f'Test MSE: {test_mse:.4f}')\n",
    "print(f'Test MAE: {test_mae:.4f}')\n",
    "print(f'Test RMSE: {test_rmse:.4f}')\n",
    "\n",
    "results_df.head()  # Print the first few rows of the results DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30260.000000</td>\n",
       "      <td>30260.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.016954</td>\n",
       "      <td>-0.003607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.129097</td>\n",
       "      <td>0.121415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.348522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.029514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.019089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.007654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.434015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Actual     Predicted\n",
       "count  30260.000000  30260.000000\n",
       "mean       0.016954     -0.003607\n",
       "std        0.129097      0.121415\n",
       "min        0.000001     -0.348522\n",
       "25%        0.000001     -0.029514\n",
       "50%        0.000001     -0.019089\n",
       "75%        0.000001     -0.007654\n",
       "max        0.999998      1.434015"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
